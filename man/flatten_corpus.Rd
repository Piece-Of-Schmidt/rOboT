% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/03_corpus_preprocessing.R
\name{flatten_corpus}
\alias{flatten_corpus}
\title{Downsample corpus to reduce frequency spikes}
\usage{
flatten_corpus(corp, unit = "month", reference = "mean", fct = 1, seed = 1337)
}
\arguments{
\item{corp}{A \code{textmeta} object (from \pkg{tosca}).}

\item{unit}{Time unit for grouping (default: \code{"month"}).}

\item{reference}{A function name (as string) to compute the central tendency (default: \code{"mean"}).}

\item{fct}{A numeric multiplier applied to the standard deviation to define the sampling threshold (default: \code{1}).}

\item{seed}{Seed for reproducible random sampling (default: \code{1337}).}
}
\value{
A new \code{textmeta} object where date chunks with unusually high counts are downsampled.
}
\description{
Detects and flattens unusually large date chunks (e.g., sudden spikes in article counts)
by sampling documents within those time slices. Helps to normalize corpora before modeling.
}
\examples{
# flattened <- flatten_corpus(corpus, unit = "month", reference = "median", fct = 1.5)
}
